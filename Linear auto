import torch as t
import torch.nn as nn
import torch.nn.functional as F
from torch import optim
from torch.autograd import Variable as V

def get_fake_data(batch_size=8):
    x = t.rand(batch_size,1) * 20
    y = x*2+(1+t.randn(batch_size,1))*3
    return x,y

w = V(t.rand(1,1),requires_grad=True)
b = V(t.rand(1,1),requires_grad=True)

lr = 0.001
for ii in range(800):
    x,y = get_fake_data()
    x,y = V(x),V(y)
    
    #forward
    y_pred = x.mm(w) + b
    loss = 0.5*(y_pred-y)**2
    loss=loss.sum()
    
    #backward
    loss.backward()
    
    #update para
    w.data.sub_(lr*w.grad.data)
    b.data.sub_(lr*b.grad.data)
    
    #梯度清零
    w.grad.data.zero_()
    b.grad.data.zero_()
    
print(w,b)
